# This is a basic workflow to help you get started with Actions

name: Update Database

concurrency: 
  group: database-build


# Controls when the action will run. 
on:
  schedule:
    # * is a special character in YAML so you have to quote this string
    - cron:  '15 10 * * *'    

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # Add "id-token" with the intended permissions.
    permissions:
      contents: 'write'
      id-token: 'write'  
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3
      - id: 'auth'
        uses: 'google-github-actions/auth@v0'
        with:
            workload_identity_provider: 'projects/1057911442537/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
            service_account: 'my-service-account@fgregg-puddle.iam.gserviceaccount.com'
      - name: Set up Cloud Run
        uses: google-github-actions/setup-gcloud@v0
      - name: set longer cloud build timeout
        run: |
          gcloud config set builds/timeout 1800
          gcloud config get builds/timeout
      - name: dependencies
        run: |
          pip install sqlite-utils
          pip install https://github.com/fgregg/datasette/archive/refs/heads/no_limit_csv_publish.zip
      - name: get databases
        env:
          UNZIP_PASSWORD: ${{ secrets.UNZIP_PASSWORD }}
          UNZIP_PASSWORD_2022: ${{ secrets.UNZIP_PASSWORD_2022 }}
        run: |
          wget https://github.com/datamade/chicago-council-scrapers/releases/download/nightly/chicago_council.db.zip
          unzip chicago_council.db.zip
          rm chicago_council.db.zip
          sqlite-utils create-index chicago_council.db bill -- -created_at
          sqlite-utils create-index chicago_council.db billaction -- -date
          sqlite-utils create-index chicago_council.db event -- -start_date
          sqlite-utils create-index chicago_council.db voteevent -- -start_date
          wget https://github.com/fgregg/ilcampaigncash/releases/download/nightly/il_campaign_disclosure.db.zip
          unzip il_campaign_disclosure.db.zip
          rm il_campaign_disclosure.db.zip
          cat scripts/make_donation.sql | sqlite3 il_campaign_disclosure.db
          sqlite-utils create-index il_campaign_disclosure.db receipts committee_id
          sqlite-utils create-index il_campaign_disclosure.db receipts filed_doc_id
          sqlite-utils create-index il_campaign_disclosure.db expenditures committee_id
          sqlite-utils create-index il_campaign_disclosure.db expenditures filed_doc_id
          sqlite-utils create-index il_campaign_disclosure.db d2_reports committee_id
          sqlite-utils create-index il_campaign_disclosure.db d2_reports filed_doc_id
          sqlite-utils create-index il_campaign_disclosure.db filed_docs committee_id
          sqlite-utils create-index il_campaign_disclosure.db donation amount
          sqlite-utils create-index il_campaign_disclosure.db donation received_date
          sqlite-utils analyze il_campaign_disclosure.db
          wget https://github.com/fgregg/cmap-legistar/releases/download/nightly/cmap.db.zip
          unzip cmap.db.zip
          rm cmap.db.zip
          wget https://github.com/fgregg/cast-vote-record/releases/download/v1/cvr_2022_11.db.zip
          wget https://github.com/fgregg/cast-vote-record/releases/download/v1/cvr_2024_11.db.zip
          unzip -P "$UNZIP_PASSWORD_2022" cvr_2022_11.db.zip
          rm cvr_2022_11.db.zip
          unzip cvr_2024_11.db.zip
          rm cvr_2024_11.db.zip
      - name: Install Datasette plugins
        run: |
          datasette install datasette-auth-passwords datasette-auth-tokens

      - name: Get hashed Datasette password
        run: |
          # Store hash as an environment variable
          hash=$(echo '${{ secrets.DATASETTE_INSTANCE_PW }}' \
              | datasette hash-password --no-confirm); \
            echo "hash=$hash" >> $GITHUB_ENV
      - name: Deploy to Cloudrun
        run: |
          gcloud config set run/region us-central1
          gcloud config set project fgregg-puddle
          datasette publish cloudrun *.db \
            --memory 2Gi \
            --cpu 1 \
            --max-instances=2 \
            --service puddle \
            --extra-options="--crossdb --setting sql_time_limit_ms 100000 --cors --setting facet_time_limit_ms 500 --setting allow_facet off --setting trace_debug 1" \
            -m metadata.yml \
            --install=datasette-atom \
            --install=datasette-rure \
            --install=pysqlite3-binary \
            --install=datasette-hashed-urls \
            --install=datasette-block-robots \
            --install=datasette-pretty-traces \
            --install datasette-auth-passwords \
            --install datasette-datatable \
            --plugin-secret datasette-auth-passwords root_password_hash '${{ env.hash }}' \
            --version-note=$GITHUB_RUN_NUMBER
      - name: keepalive
        uses: gautamkrishnar/keepalive-workflow@1.1.0    
